---
layout: about
title: about
permalink: /
subtitle: Researcher at <a href='https://www.ugent.be/ea/idlab/en'>IDLab</a>, Ghent University - imec

profile:
  align: right
  image: ciem_profile.png
  image_circular: false # crops the image to make it circular
  more_info: >
    <p>IDLab, Department of Information Technology</p>
    <p>Ghent University - imec</p>
    <p>Ghent, Belgium</p>

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: true
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

I am a PhD researcher at [IDLab](https://www.ugent.be/ea/idlab/en), Department of Information Technology at Ghent University - imec, where I specialize in adaptive sensor fusion for autonomous systems with applications in precision agriculture and environmental monitoring. My research focuses on developing robust AI-driven perception systems that bridge fundamental machine learning innovation with real-world deployment challenges.

My academic journey reflects a deliberate progression from fundamental science to applied AI. I completed my Bachelor's and Master's in Physics at Ghent University, where I developed strong analytical foundations and an aptitude for dissecting complex problems at their core. During my physics master's, elective courses in artificial intelligence sparked a passion that led me to pursue an Advanced Master's in Artificial Intelligence at KU Leuven (2023), where I specialized in deep learning, computer vision, and data science. This trajectory has uniquely positioned me to tackle the multi-modal sensor fusion challenges central to my PhD research.

My current research centers on the synergistic combination of **Hyperspectral Imaging (HSI)**, **RGB and SWIR sensors**, **Unmanned Aerial Vehicles (UAVs)**, and **Deep Learning**—particularly transformer-based architectures. I develop end-to-end systems that transform raw multi-modal sensor data from autonomous platforms into actionable insights. A key focus is making these AI systems practically deployable in uncontrolled field environments by addressing challenges like variable illumination, limited computational resources on edge devices, spectral-spatial trade-offs, and the need for real-time processing.

**Key Research Contributions:**
- Developed **LISA** (Light-Invariant Spectral Autoencoder), a domain-adversarial deep learning framework enabling robust, non-destructive grape quality assessment under varying illumination—part of a complete IoT-enabled robotic system for precision viticulture
- Created **OHSLIC** (Online Hyperspectral Simple Linear Iterative Clustering), an efficient algorithm achieving real-time phenotype segmentation on resource-constrained UAVs through adaptive, on-device processing
- Co-authored research on computational fairness in adaptive neural networks, introducing resource allocation disparities as a novel dimension of algorithmic fairness and highlighting ethical considerations in efficiency-driven AI

My work has been published in leading venues including the **IEEE Internet of Things Journal**, **IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)**, and **Neural Computing and Applications**. Beyond research, I serve as a Teaching Assistant for the Reinforcement Learning course at Ghent University (2024-2026) and supervise master's thesis students on topics spanning hyperspectral imaging, deep learning for precision agriculture, and multi-modal sensor fusion.

I am driven by a deep fascination with AI's transformative potential for autonomous systems, particularly in optimizing real-time perception through adaptive sensor fusion. My research philosophy centers on identifying fundamental deployment barriers in real-world environments and developing innovative, domain-invariant solutions that advance both the theoretical foundations and practical applicability of AI-driven perception systems.
